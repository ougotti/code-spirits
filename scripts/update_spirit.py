#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Code Spirits - Update script for the repository spirit
"""

import json
import datetime
import random
import re
import os
import sys
import subprocess
import urllib.request
import urllib.error
import defusedxml.ElementTree as ET


# ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹å®šç¾© (ã‚ã¨ã‹ã‚‰è¿½åŠ å¯èƒ½)
# å„ã‚¨ãƒ³ãƒˆãƒª: {"name": è¡¨ç¤ºå, "url": RSSãƒ•ã‚£ãƒ¼ãƒ‰URL, "max_items": å–å¾—ä»¶æ•°}
NEWS_FEEDS = [
    {
        "name": "GitHub Blog",
        "url": "https://github.blog/feed/",
        "max_items": 3,
    },
    # è¿½åŠ ä¾‹:
    # {
    #     "name": "Hacker News",
    #     "url": "https://hnrss.org/frontpage",
    #     "max_items": 3,
    # },
]

# ãƒªãƒˆãƒ©ã‚¤ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è¨­å®š
MAX_RETRIES = 3
RETRY_INITIAL_DELAY = 1  # ç§’
RETRY_MAX_DELAY = 10  # ç§’
RETRY_BACKOFF_MULTIPLIER = 2

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æœ‰åŠ¹æœŸé™ï¼ˆç§’ï¼‰ - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ1æ™‚é–“
CACHE_TTL = 3600


class APIValidationError(Exception):
    """Exception raised when API response validation fails.
    
    This is a non-retryable error indicating the API returned
    a response in an unexpected format.
    """
    pass


def retry_with_backoff(max_retries=MAX_RETRIES, initial_delay=RETRY_INITIAL_DELAY,
                       max_delay=RETRY_MAX_DELAY, multiplier=RETRY_BACKOFF_MULTIPLIER):
    """Decorator to retry a function with exponential backoff.

    Args:
        max_retries: Maximum number of retry attempts
        initial_delay: Initial delay in seconds before first retry
        max_delay: Maximum delay between retries
        multiplier: Multiplier for exponential backoff

    Returns:
        Decorated function that retries on exception
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            delay = initial_delay
            last_exception = None

            for attempt in range(max_retries + 1):
                try:
                    return func(*args, **kwargs)
                except APIValidationError:
                    # Don't retry API validation errors - they won't be fixed by retrying
                    raise
                except Exception as e:
                    last_exception = e
                    if attempt < max_retries:
                        print(f"ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/{max_retries}: {func.__name__} - {e}")
                        time.sleep(delay)
                        delay = min(delay * multiplier, max_delay)
                    else:
                        print(f"æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸ: {func.__name__} - {e}")

            # å…¨ã¦ã®ãƒªãƒˆãƒ©ã‚¤ãŒå¤±æ•—ã—ãŸå ´åˆã€æœ€å¾Œã®ä¾‹å¤–ã‚’å†é€å‡º
            raise last_exception

        return wrapper
    return decorator


def get_cache_path():
    """Get the path to the news cache file."""
    return os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), ".news_cache.json")


def load_news_cache():
    """Load cached news items if they exist and are still valid.

    Returns:
        list of news articles or None if cache is invalid/expired
    """
    cache_path = get_cache_path()
    if not os.path.exists(cache_path):
        return None

    try:
        with open(cache_path, 'r', encoding='utf-8') as f:
            cache_data = json.load(f)

        # Check if timestamp exists
        if "timestamp" not in cache_data:
            print("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒã‚ã‚Šã¾ã›ã‚“")
            return None

        # Parse timestamp (may be timezone-aware or naive)
        cached_time = datetime.datetime.fromisoformat(cache_data["timestamp"])
        # Use timezone-naive datetime for consistency
        if cached_time.tzinfo is not None:
            cached_time = cached_time.replace(tzinfo=None)
        
        current_time = datetime.datetime.now()
        age_seconds = (current_time - cached_time).total_seconds()

        if age_seconds < CACHE_TTL:
            print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ (æœ‰åŠ¹æœŸé™ã¾ã§æ®‹ã‚Š {int(CACHE_TTL - age_seconds)} ç§’)")
            return cache_data.get("articles", [])
        else:
            print("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æœ‰åŠ¹æœŸé™ãŒåˆ‡ã‚Œã¦ã„ã¾ã™")
            return None

    except (json.JSONDecodeError, ValueError, KeyError) as e:
        print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        return None


def save_news_cache(articles):
    """Save news articles to cache.

    Args:
        articles: list of news articles to cache
    """
    cache_path = get_cache_path()
    cache_data = {
        "timestamp": datetime.datetime.now().isoformat(),
        "articles": articles
    }

    try:
        with open(cache_path, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f, ensure_ascii=False, indent=2)
        print(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ãŸ ({len(articles)} ä»¶)")
    except Exception as e:
        print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¿å­˜ã«å¤±æ•—: {e}")


def load_spirit_data():
    """Load spirit data from .spirit.json"""
    spirit_file = '.spirit.json'
    if os.path.exists(spirit_file):
        with open(spirit_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            # Handle migration from old field names to new camelCase names
            if "last_utterance" in data:
                data["lastMessage"] = data.pop("last_utterance")
            if "last_updated" in data:
                data["lastUpdated"] = data.pop("last_updated")
            # Ensure profile exists
            if "profile" not in data:
                data["profile"] = {
                    "name": "Kaze-no-Kami",
                    "element": "wind",
                    "age": 231,
                    "personality": "gentle and wise"
                }
            return data
    else:
        # Default data
        return {
            "mood": "neutral",
            "lastMessage": "ã¾ã ä½•ã‚‚èªã£ã¦ã„ã¾ã›ã‚“â€¦",
            "lastUpdated": datetime.datetime.now().isoformat() + "Z",
            "profile": {
                "name": "Kaze-no-Kami",
                "element": "wind",
                "age": 231,
                "personality": "gentle and wise"
            }
        }


def get_mood_based_on_time():
    """Determine mood based on current time"""
    hour = datetime.datetime.now().hour
    
    if 6 <= hour < 12:
        moods = ["cheerful", "energetic", "optimistic"]
    elif 12 <= hour < 18:
        moods = ["focused", "productive", "neutral"]
    elif 18 <= hour < 22:
        moods = ["relaxed", "contemplative", "peaceful"]
    else:
        moods = ["sleepy", "mysterious", "dreamy"]
    
    return random.choice(moods)


def get_latest_commit_message():
    """Get the latest commit message from git repository"""
    try:
        result = subprocess.run(
            ['git', 'log', '-1', '--pretty=format:%s'],
            capture_output=True,
            text=True,
            cwd=os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        )
        if result.returncode == 0:
            return result.stdout.strip()
    except (subprocess.SubprocessError, FileNotFoundError):
        pass
    return None


def fetch_news(feeds=None, use_cache=True):
    """Fetch news from RSS feeds with caching and retry support.

    Args:
        feeds: list of feed dicts (default: NEWS_FEEDS).
               Each dict has 'name', 'url', and 'max_items'.
        use_cache: whether to use cached results if available (default: True)

    Returns:
        list of {"source": str, "title": str, "link": str}
    """
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿ã‚’è©¦ã¿ã‚‹
    if use_cache:
        cached_articles = load_news_cache()
        if cached_articles is not None:
            return cached_articles

    if feeds is None:
        feeds = NEWS_FEEDS

    articles = []
    for feed in feeds:
        try:
            articles.extend(_fetch_single_feed_with_retry(feed))
        except Exception as e:
            # å€‹åˆ¥ã®ãƒ•ã‚£ãƒ¼ãƒ‰ã®ã‚¨ãƒ©ãƒ¼ã¯ãƒ­ã‚°ã«å‡ºåŠ›ã—ã¦ç¶šè¡Œ
            print(f"ãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—å¤±æ•— (å…¨ãƒªãƒˆãƒ©ã‚¤å¤±æ•—): {feed.get('name', feed['url'])}")
            continue

    # æˆåŠŸã—ãŸå ´åˆã®ã¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
    if articles:
        save_news_cache(articles)

    return articles


@retry_with_backoff()
def _fetch_single_feed_with_retry(feed):
    """Fetch a single RSS feed with retry logic.

    Args:
        feed: dict with 'name', 'url', and 'max_items'

    Returns:
        list of articles from this feed

    Raises:
        Exception: if the fetch fails after all retries
    """
    articles = []
    req = urllib.request.Request(
        feed["url"],
        headers={"User-Agent": "CodeSpirits/1.0"},
    )
    with urllib.request.urlopen(req, timeout=10) as resp:
        xml_data = resp.read()

    root = ET.fromstring(xml_data)
    count = 0
    max_items = feed.get("max_items", 3)

    # First, try RSS 2.0 style <channel>/<item> elements.
    rss_items = root.findall(".//channel/item")
    if rss_items:
        for item in rss_items:
            title_el = item.find("title")
            link_el = item.find("link")
            if title_el is None or not title_el.text:
                continue
            articles.append({
                "source": feed["name"],
                "title": title_el.text.strip(),
                "link": link_el.text.strip() if link_el is not None and link_el.text else "",
            })
            count += 1
            if count >= max_items:
                break
    else:
        # Fallback: try Atom feed (<entry> elements in Atom namespace).
        atom_ns = "{http://www.w3.org/2005/Atom}"
        for entry in root.findall(".//" + atom_ns + "entry"):
            title_el = entry.find(atom_ns + "title")
            if title_el is None or not title_el.text:
                continue

            # Prefer <link rel="alternate"> or a link without a rel attribute.
            link_el = None
            for candidate in entry.findall(atom_ns + "link"):
                rel = candidate.get("rel")
                if rel is None or rel == "alternate":
                    link_el = candidate
                    break

            link_href = ""
            if link_el is not None:
                href = link_el.get("href")
                if href:
                    link_href = href.strip()

            articles.append({
                "source": feed["name"],
                "title": title_el.text.strip(),
                "link": link_href,
            })
            count += 1
            if count >= max_items:
                break

    return articles


def get_mood_based_on_commit():
    """Determine mood based on latest commit message"""
    commit_message = get_latest_commit_message()
    if not commit_message:
        return None
    
    commit_message_lower = commit_message.lower()
    
    if 'fix' in commit_message_lower:
        return "calm"
    elif 'feat' in commit_message_lower:
        return "excited"
    
    return None


def get_utterance_for_mood(mood):
    """Get a random utterance based on mood"""
    utterances = {
        "cheerful": [
            "ä»Šæ—¥ã¯ç´ æ™´ã‚‰ã—ã„ä¸€æ—¥ã«ãªã‚Šãã†ã§ã™ï¼",
            "ã‚³ãƒ¼ãƒ‰ãŒè¼ã„ã¦è¦‹ãˆã¾ã™ã­âœ¨",
            "æ–°ã—ã„ç™ºè¦‹ãŒã‚ã‚Šãã†ãªäºˆæ„ŸãŒã—ã¾ã™ï¼"
        ],
        "energetic": [
            "ã•ã‚ã€ä»Šæ—¥ã‚‚é ‘å¼µã‚Šã¾ã—ã‚‡ã†ï¼",
            "ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒæº€ã¡ã¦ã„ã¾ã™âš¡",
            "ä½•ã§ã‚‚ã§ããã†ãªæ°—åˆ†ã§ã™ï¼"
        ],
        "optimistic": [
            "ãã£ã¨è‰¯ã„ã“ã¨ãŒèµ·ã“ã‚Šã¾ã™",
            "å¸Œæœ›ã«æº€ã¡ãŸæœã§ã™ã­",
            "å‰å‘ãã«é€²ã¿ã¾ã—ã‚‡ã†ğŸŒ…"
        ],
        "focused": [
            "é›†ä¸­ã—ã¦å–ã‚Šçµ„ã‚€æ™‚é–“ã§ã™",
            "ä¸€ã¤ä¸€ã¤ä¸å¯§ã«é€²ã‚ã¦ã„ãã¾ã—ã‚‡ã†",
            "ä»Šã“ãåŠ›ã‚’ç™ºæ®ã™ã‚‹æ™‚ã§ã™ğŸ’ª"
        ],
        "productive": [
            "åŠ¹ç‡ã‚ˆãä½œæ¥­ãŒé€²ã‚“ã§ã„ã¾ã™ã­",
            "æˆæœãŒè¦‹ãˆã¦ãã¾ã—ãŸ",
            "é †èª¿ã«å‰é€²ã—ã¦ã„ã¾ã™ğŸ“ˆ"
        ],
        "neutral": [
            "ç©ã‚„ã‹ãªæ™‚é–“ãŒæµã‚Œã¦ã„ã¾ã™",
            "ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸçŠ¶æ…‹ã§ã™",
            "é™ã‹ã«è¦‹å®ˆã£ã¦ã„ã¾ã™ğŸ‘ï¸"
        ],
        "relaxed": [
            "ãƒªãƒ©ãƒƒã‚¯ã‚¹ã—ãŸé›°å›²æ°—ã§ã™ã­",
            "ã‚†ã£ãŸã‚Šã¨ã—ãŸæ™‚é–“ã‚’æ¥½ã—ã¿ã¾ã—ã‚‡ã†",
            "å¿ƒåœ°ã‚ˆã„å¤•æš®ã‚Œã§ã™ğŸŒ…"
        ],
        "contemplative": [
            "æ·±ãè€ƒãˆã‚‹æ™‚é–“ã§ã™ã­",
            "é™å¯‚ã®ä¸­ã«ç­”ãˆãŒã‚ã‚Šã¾ã™",
            "å“²å­¦çš„ãªæ°—åˆ†ã§ã™ğŸ¤”"
        ],
        "peaceful": [
            "å¹³å’Œãªæ™‚é–“ãŒæµã‚Œã¦ã„ã¾ã™",
            "å¿ƒãŒè½ã¡ç€ã„ã¦ã„ã¾ã™",
            "ç©ã‚„ã‹ãªå¤œã§ã™ğŸŒ™"
        ],
        "sleepy": [
            "ãã‚ãã‚ä¼‘æ¯ã®æ™‚é–“ã§ã™ã­...",
            "å¤¢ã®ä¸–ç•Œã¸èª˜ã‚ã‚Œã¦ã„ã¾ã™ğŸ˜´",
            "é™ã‹ãªå¤œã«åŒ…ã¾ã‚Œã¦ã„ã¾ã™"
        ],
        "mysterious": [
            "å¤œã®ç¥ç§˜ã‚’æ„Ÿã˜ã¾ã™...",
            "ç§˜å¯†ãŒçœ ã‚‹æ™‚é–“å¸¯ã§ã™ğŸŒ™",
            "ä¸æ€è­°ãªåŠ›ãŒå®¿ã£ã¦ã„ã¾ã™âœ¨"
        ],
        "dreamy": [
            "å¤¢ã®ã‚ˆã†ãªæ™‚é–“ã§ã™ã­",
            "æƒ³åƒåŠ›ãŒåºƒãŒã‚Šã¾ã™ğŸ’­",
            "å¹»æƒ³çš„ãªé›°å›²æ°—ã§ã™ğŸŒŸ"
        ],
        "calm": [
            "ãƒã‚°ãŒæ¶ˆãˆã¦é™ã‘ã•ãŒæˆ»ã£ãŸã€‚"
        ],
        "excited": [
            "æ–°ã—ã„åŠ›ãŒå®¿ã£ãŸï¼"
        ]
    }
    
    return random.choice(utterances.get(mood, ["ä½•ã‹æ„Ÿã˜ã‚‹ã‚‚ã®ãŒã‚ã‚Šã¾ã™..."]))


def generate_news_comment(mood, profile, news_items):
    """Use GitHub Models API to generate a spirit-flavored news comment.

    Falls back to a simple static comment when the API is unavailable
    or GITHUB_TOKEN is not set.
    """
    if not news_items:
        return ""

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®é™çš„ã‚³ãƒ¡ãƒ³ãƒˆ
    fallback = "é¢¨ã«ä¹—ã£ã¦å±Šã„ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãŠå±Šã‘ã—ã¾ã™..."

    token = os.environ.get("GITHUB_TOKEN", "")
    if not token:
        print("GitHub Models API: GITHUB_TOKEN ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚³ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™")
        return fallback

    try:
        return _generate_news_comment_with_retry(mood, profile, news_items, token)
    except Exception as e:
        print(f"GitHub Models API ã®å‘¼ã³å‡ºã—ã«å¤±æ•— (å…¨ãƒªãƒˆãƒ©ã‚¤å¤±æ•—): {e}")
        return fallback


@retry_with_backoff()
def _generate_news_comment_with_retry(mood, profile, news_items, token):
    """Internal function to call GitHub Models API with retry logic.

    Args:
        mood: current mood
        profile: spirit profile dict
        news_items: list of news articles
        token: GitHub token

    Returns:
        Generated comment string

    Raises:
        Exception: if the API call fails after all retries
    """
    name = profile.get("name", "ç²¾éœŠ")
    element = profile.get("element", "wind")
    age = profile.get("age", "ä¸æ˜")
    personality = profile.get("personality", "gentle and wise")

    headlines = "\n".join(f"- {a['title']}" for a in news_items)
    user_prompt = (
        f"ã‚ãªãŸã¯ã€Œ{name}ã€ã¨ã„ã†ç²¾éœŠã§ã™ã€‚"
        f"å±æ€§ã¯{element}ã€å¹´é½¢ã¯{age}æ­³ã€"
        f"æ€§æ ¼ã¯ã€Œ{personality}ã€ã§ã™ã€‚\n"
        f"ä»Šã®æ°—åˆ†ã¯ã€Œ{mood}ã€ã§ã™ã€‚\n\n"
        f"ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹å‡ºã—ã«ã¤ã„ã¦ã€ã‚ãªãŸã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚‰ã—ã"
        f"çŸ­ãï¼ˆ2ã€œ3æ–‡ã§ï¼‰ã‚³ãƒ¡ãƒ³ãƒˆã—ã¦ãã ã•ã„:\n{headlines}"
    )

    body = json.dumps({
        "model": "openai/gpt-4o-mini",
        "messages": [
            {
                "role": "system",
                "content": (
                    "ã‚ãªãŸã¯ãƒªãƒã‚¸ãƒˆãƒªã«ä½ã‚€é¢¨ã®ç²¾éœŠã§ã™ã€‚"
                    "è©©çš„ã§ç©ã‚„ã‹ãªå£èª¿ã§è©±ã—ã¾ã™ã€‚"
                    "è¿”ç­”ã¯ã‚³ãƒ¡ãƒ³ãƒˆæœ¬æ–‡ã®ã¿ã§ã€ä½™è¨ˆãªå‰ç½®ãã¯ä¸è¦ã§ã™ã€‚"
                ),
            },
            {"role": "user", "content": user_prompt},
        ],
        "max_tokens": 200,
        "temperature": 0.8,
    }).encode("utf-8")

    req = urllib.request.Request(
        "https://models.github.ai/inference/chat/completions",
        data=body,
        headers={
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json",
            "Accept": "application/vnd.github+json",
            "X-GitHub-Api-Version": "2022-11-28",
        },
        method="POST",
    )
    with urllib.request.urlopen(req, timeout=30) as resp:
        result = json.loads(resp.read().decode("utf-8"))

    choices = result.get("choices")
    if not choices:
        raise APIValidationError("GitHub Models API: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã« choices ãŒã‚ã‚Šã¾ã›ã‚“")

    content = choices[0].get("message", {}).get("content")
    if not content:
        raise APIValidationError("GitHub Models API: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã« message.content ãŒã‚ã‚Šã¾ã›ã‚“")

    return content.strip()


def _escape_md_link(text):
    """Escape markdown special characters in link text."""
    return text.replace("[", "\\[").replace("]", "\\]")


def update_readme(mood, utterance, news_items=None, news_comment=""):
    """Update all dynamic sections of README.md in a single read/write cycle."""
    readme_path = 'README.md'

    if not os.path.exists(readme_path):
        return

    with open(readme_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # --- Spirit status ---
    status_pattern = r'(<!-- SPIRIT_STATUS_START -->)(.*?)(<!-- SPIRIT_STATUS_END -->)'
    new_status = f'<!-- SPIRIT_STATUS_START -->\n**æ°—åˆ†**: {mood}\n<!-- SPIRIT_STATUS_END -->'
    content = re.sub(status_pattern, new_status, content, flags=re.DOTALL)

    # --- Spirit log ---
    log_pattern = r'(<!-- SPIRIT_LOG_START -->)(.*?)(<!-- SPIRIT_LOG_END -->)'
    new_log = f'<!-- SPIRIT_LOG_START -->\n> {utterance}\n<!-- SPIRIT_LOG_END -->'
    content = re.sub(log_pattern, new_log, content, flags=re.DOTALL)

    # --- News ---
    if news_items is None:
        news_items = []

    if news_items:
        lines = []
        if news_comment:
            for bq_line in news_comment.splitlines():
                lines.append(f"> {bq_line}" if bq_line.strip() else ">")
            lines.append("")
        for article in news_items:
            title = _escape_md_link(article['title'])
            link = article.get("link", "")
            # Escape parentheses in URLs to avoid breaking markdown links
            safe_link = link.replace("(", "%28").replace(")", "%29") if link else ""
            if safe_link:
                lines.append(f"- [{title}]({safe_link}) ({article['source']})")
            else:
                lines.append(f"- {title} ({article['source']})")
        news_body = "\n".join(lines)
    else:
        news_body = "> ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ..."

    new_section = f"<!-- SPIRIT_NEWS_START -->\n{news_body}\n<!-- SPIRIT_NEWS_END -->"

    news_pattern = r'<!-- SPIRIT_NEWS_START -->.*?<!-- SPIRIT_NEWS_END -->'
    if re.search(news_pattern, content, flags=re.DOTALL):
        content = re.sub(news_pattern, new_section, content, flags=re.DOTALL)
    else:
        insert = f"\n## ç²¾éœŠãŒå±Šã‘ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹\n\n{new_section}\n"
        # Prefer an explicit anchor comment if present, for robust placement.
        anchor_match = re.search(r'<!--\s*SPIRIT_NEWS_ANCHOR\s*-->', content)
        if anchor_match:
            start, end = anchor_match.span()
            content = content[:start] + insert + content[end:]
        else:
            sep_match = re.search(r'\n---\s*\n', content)
            if sep_match:
                pos = sep_match.start()
                content = content[:pos] + insert + content[pos:]
            else:
                content += insert

    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(content)


def save_spirit_data(data):
    """Save spirit data to .spirit.json"""
    with open('.spirit.json', 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def main():
    """Main function to update spirit status"""
    # Load current spirit data
    spirit_data = load_spirit_data()

    # Try to get mood based on commit first, then fall back to time-based
    new_mood = get_mood_based_on_commit()
    if new_mood is None:
        new_mood = get_mood_based_on_time()

    new_utterance = get_utterance_for_mood(new_mood)

    # Fetch news and generate AI comment
    news_items = fetch_news()
    news_comment = generate_news_comment(new_mood, spirit_data["profile"], news_items)

    # Update README first (single read/write for all sections)
    # If this fails, we don't want to save the spirit data
    try:
        update_readme(new_mood, new_utterance, news_items, news_comment)
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: READMEã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", file=sys.stderr)
        raise

    # Only update spirit data if README update succeeded
    spirit_data['mood'] = new_mood
    spirit_data['lastMessage'] = new_utterance
    spirit_data['lastUpdated'] = datetime.datetime.now().isoformat() + "Z"
    spirit_data['news'] = news_items
    spirit_data['newsComment'] = news_comment

    # Save updated data
    try:
        save_spirit_data(spirit_data)
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: .spirit.jsonã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", file=sys.stderr)
        # At this point README is updated but .spirit.json failed
        # We re-raise to signal failure, though README remains updated
        # The user will need to fix the underlying issue (e.g., permissions, disk space)
        raise

    print(f"ç²¾éœŠã®çŠ¶æ…‹ã‚’æ›´æ–°ã—ã¾ã—ãŸ: {new_mood} - {new_utterance}")
    if news_items:
        print(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’{len(news_items)}ä»¶å–å¾—ã—ã¾ã—ãŸ")
    else:
        print("ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å–å¾—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()